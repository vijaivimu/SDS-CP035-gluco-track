{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed099bc",
   "metadata": {},
   "source": [
    "**1: Import Libraries and Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9260cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üéØ Week 2: Feature Engineering & Deep Learning Preparation\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    LabelEncoder,\n",
    ")\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üéØ Week 2: Feature Engineering & Deep Learning Preparation\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4418a06",
   "metadata": {},
   "source": [
    "**Import dataset again (same as week 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>demographic</th>\n",
       "      <th>description</th>\n",
       "      <th>units</th>\n",
       "      <th>missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighBP</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>0 = no high BP 1 = high BP</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HighChol</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>0 = no high cholesterol 1 = high cholesterol</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CholCheck</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMI</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smoker</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stroke</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>(Ever told) you had a stroke. 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HeartDiseaseorAttack</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>coronary heart disease (CHD) or myocardial infarction (MI) 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PhysActivity</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>physical activity in past 30 days - not including job 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fruits</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Consume Fruit 1 or more times per day 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Veggies</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Consume Vegetables 1 or more times per day 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HvyAlcoholConsump</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AnyHealthcare</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NoDocbcCost</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GenHlth</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>Would you say that in general your health is: scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MentHlth</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? scale 1-30 days</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PhysHlth</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? scale 1-30 days</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DiffWalk</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>Do you have serious difficulty walking or climbing stairs? 0 = no 1 = yes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sex</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Sex</td>\n",
       "      <td>0 = female 1 = male</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Age</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>Age</td>\n",
       "      <td>13-level age category (_AGEG5YR see codebook) 1 = 18-24 9 = 60-64 13 = 80 or older</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Education</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>Education Level</td>\n",
       "      <td>Education level (EDUCA see codebook) scale 1-6 1 = Never attended school or only kindergarten 2 = Grades 1 through 8 (Elementary) 3 = Grades 9 through 11 (Some high school) 4 = Grade 12 or GED (High school graduate) 5 = College 1 year to 3 years (Some college or technical school) 6 = College 4 years or more (College graduate)</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Income</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>Income</td>\n",
       "      <td>Income scale (INCOME2 see codebook) scale 1-8 1 = less than $10,000 5 = less than $35,000 8 = $75,000 or more</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Diabetes_binary</td>\n",
       "      <td>Target</td>\n",
       "      <td>Binary</td>\n",
       "      <td>None</td>\n",
       "      <td>0 = no diabetes 1 = prediabetes or diabetes</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name     role     type      demographic  \\\n",
       "0   HighBP                Feature  Binary   None              \n",
       "1   HighChol              Feature  Binary   None              \n",
       "2   CholCheck             Feature  Binary   None              \n",
       "3   BMI                   Feature  Integer  None              \n",
       "4   Smoker                Feature  Binary   None              \n",
       "5   Stroke                Feature  Binary   None              \n",
       "6   HeartDiseaseorAttack  Feature  Binary   None              \n",
       "7   PhysActivity          Feature  Binary   None              \n",
       "8   Fruits                Feature  Binary   None              \n",
       "9   Veggies               Feature  Binary   None              \n",
       "10  HvyAlcoholConsump     Feature  Binary   None              \n",
       "11  AnyHealthcare         Feature  Binary   None              \n",
       "12  NoDocbcCost           Feature  Binary   None              \n",
       "13  GenHlth               Feature  Integer  None              \n",
       "14  MentHlth              Feature  Integer  None              \n",
       "15  PhysHlth              Feature  Integer  None              \n",
       "16  DiffWalk              Feature  Binary   None              \n",
       "17  Sex                   Feature  Binary   Sex               \n",
       "18  Age                   Feature  Integer  Age               \n",
       "19  Education             Feature  Integer  Education Level   \n",
       "20  Income                Feature  Integer  Income            \n",
       "21  Diabetes_binary       Target   Binary   None              \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                description  \\\n",
       "0   0 = no high BP 1 = high BP                                                                                                                                                                                                                                                                                                                \n",
       "1   0 = no high cholesterol 1 = high cholesterol                                                                                                                                                                                                                                                                                              \n",
       "2   0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years                                                                                                                                                                                                                                                                  \n",
       "3   Body Mass Index                                                                                                                                                                                                                                                                                                                           \n",
       "4   Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no 1 = yes                                                                                                                                                                                                                              \n",
       "5   (Ever told) you had a stroke. 0 = no 1 = yes                                                                                                                                                                                                                                                                                              \n",
       "6   coronary heart disease (CHD) or myocardial infarction (MI) 0 = no 1 = yes                                                                                                                                                                                                                                                                 \n",
       "7   physical activity in past 30 days - not including job 0 = no 1 = yes                                                                                                                                                                                                                                                                      \n",
       "8   Consume Fruit 1 or more times per day 0 = no 1 = yes                                                                                                                                                                                                                                                                                      \n",
       "9   Consume Vegetables 1 or more times per day 0 = no 1 = yes                                                                                                                                                                                                                                                                                 \n",
       "10  Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no 1 = yes                                                                                                                                                                                                          \n",
       "11  Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes                                                                                                                                                                                                                         \n",
       "12  Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes                                                                                                                                                                                                                      \n",
       "13  Would you say that in general your health is: scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor                                                                                                                                                                                                                            \n",
       "14  Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? scale 1-30 days                                                                                                                                          \n",
       "15  Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? scale 1-30 days                                                                                                                                                         \n",
       "16  Do you have serious difficulty walking or climbing stairs? 0 = no 1 = yes                                                                                                                                                                                                                                                                 \n",
       "17  0 = female 1 = male                                                                                                                                                                                                                                                                                                                       \n",
       "18  13-level age category (_AGEG5YR see codebook) 1 = 18-24 9 = 60-64 13 = 80 or older                                                                                                                                                                                                                                                        \n",
       "19  Education level (EDUCA see codebook) scale 1-6 1 = Never attended school or only kindergarten 2 = Grades 1 through 8 (Elementary) 3 = Grades 9 through 11 (Some high school) 4 = Grade 12 or GED (High school graduate) 5 = College 1 year to 3 years (Some college or technical school) 6 = College 4 years or more (College graduate)   \n",
       "20  Income scale (INCOME2 see codebook) scale 1-8 1 = less than $10,000 5 = less than $35,000 8 = $75,000 or more                                                                                                                                                                                                                             \n",
       "21  0 = no diabetes 1 = prediabetes or diabetes                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "   units missing_values  \n",
       "0   None  no             \n",
       "1   None  no             \n",
       "2   None  no             \n",
       "3   None  no             \n",
       "4   None  no             \n",
       "5   None  no             \n",
       "6   None  no             \n",
       "7   None  no             \n",
       "8   None  no             \n",
       "9   None  no             \n",
       "10  None  no             \n",
       "11  None  no             \n",
       "12  None  no             \n",
       "13  None  no             \n",
       "14  None  no             \n",
       "15  None  no             \n",
       "16  None  no             \n",
       "17  None  no             \n",
       "18  None  no             \n",
       "19  None  no             \n",
       "20  None  no             \n",
       "21  None  no             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# fetch dataset\n",
    "datset = fetch_ucirepo(id=891)  # CDC Diabetes Health Indicators\n",
    "# data (as pandas dataframes)\n",
    "X = datset.data.features  # feature set\n",
    "y = datset.data.targets  # target variable\n",
    "# combine features and target into a single dataframe for easier analysis\n",
    "df = pd.concat([X, y], axis=1)\n",
    "# df.head()\n",
    "# Programmatically merge df columns with datset.variables metadata\n",
    "try:\n",
    "    if (\n",
    "        isinstance(datset.variables, pd.DataFrame)\n",
    "        and \"name\" in datset.variables.columns\n",
    "    ):\n",
    "        df_columns = pd.DataFrame({\"name\": df.columns})\n",
    "        merged = pd.merge(datset.variables, df_columns, on=\"name\", how=\"right\")\n",
    "        pd.set_option(\"display.max_colwidth\", True)\n",
    "        display(merged)\n",
    "    else:\n",
    "        print(\"datset.variables is not a DataFrame with a 'name' column.\")\n",
    "        print(datset.variables)\n",
    "except Exception as e:\n",
    "    print(\"Error combining variables:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298e963",
   "metadata": {},
   "source": [
    "#### 2. Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3a98e",
   "metadata": {},
   "source": [
    "**2.1 Remove duplicate rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====DELETE DUPLICATE ROWS=====\n",
      "Original dataset (df) shape: (253680, 22)\n",
      "Duplicate rows: 24206\n",
      "Cleaned dataset (df_dedupe) shape: (229474, 22)\n",
      "Number of rows removed: 24206\n",
      "\n",
      "‚úÖ All duplicate rows removed\n"
     ]
    }
   ],
   "source": [
    "print(\"====DELETE DUPLICATE ROWS=====\")\n",
    "## Original dataset shape\n",
    "print(\"Original dataset (df) shape:\", df.shape)\n",
    "# Duplicate rows:\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "# Drop duplicates\n",
    "df_dedupe = df.drop_duplicates()\n",
    "\n",
    "# Cleaned dataset shape\n",
    "print(\"Cleaned dataset (df_dedupe) shape:\", df_dedupe.shape)\n",
    "\n",
    "# Compare original and cleaned dataset\n",
    "print(\"Number of rows removed:\", len(df) - len(df_dedupe))\n",
    "\n",
    "print(\"\\n‚úÖ All duplicate rows removed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85af43b",
   "metadata": {},
   "source": [
    "**2.2 Optimize Data Sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b4261",
   "metadata": {},
   "source": [
    "- Optimizing data types reduces the memory footprint of your dataset, which is crucial when working with large data or limited resources.\n",
    "Downcasting numeric columns and converting suitable object columns to category types can significantly decrease RAM usage.\n",
    "Lower memory usage enables faster data processing, more efficient model training, and the ability to handle larger datasets.\n",
    "This step is especially important for scalable machine learning pipelines and neural network training, where memory efficiency directly impacts performance and feasibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aae1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA TYPE OPTIMIZATION ===\n",
      "Current data types:\n",
      "int64    22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Analyzing float64 columns for potential integer conversion:\n",
      "\n",
      "---No float64 columns found that could be converted to integers.\n",
      "\n",
      "\n",
      "Optimizing integer columns:\n",
      "  HighBP: Optimized to uint8 (range: 0-1)\n",
      "  HighChol: Optimized to uint8 (range: 0-1)\n",
      "  CholCheck: Optimized to uint8 (range: 0-1)\n",
      "  BMI: Optimized to uint8 (range: 12-98)\n",
      "  Smoker: Optimized to uint8 (range: 0-1)\n",
      "  Stroke: Optimized to uint8 (range: 0-1)\n",
      "  HeartDiseaseorAttack: Optimized to uint8 (range: 0-1)\n",
      "  PhysActivity: Optimized to uint8 (range: 0-1)\n",
      "  Fruits: Optimized to uint8 (range: 0-1)\n",
      "  Veggies: Optimized to uint8 (range: 0-1)\n",
      "  HvyAlcoholConsump: Optimized to uint8 (range: 0-1)\n",
      "  AnyHealthcare: Optimized to uint8 (range: 0-1)\n",
      "  NoDocbcCost: Optimized to uint8 (range: 0-1)\n",
      "  GenHlth: Optimized to uint8 (range: 1-5)\n",
      "  MentHlth: Optimized to uint8 (range: 0-30)\n",
      "  PhysHlth: Optimized to uint8 (range: 0-30)\n",
      "  DiffWalk: Optimized to uint8 (range: 0-1)\n",
      "  Sex: Optimized to uint8 (range: 0-1)\n",
      "  Age: Optimized to uint8 (range: 1-13)\n",
      "  Education: Optimized to uint8 (range: 1-6)\n",
      "  Income: Optimized to uint8 (range: 1-8)\n",
      "  Diabetes_binary: Optimized to uint8 (range: 0-1)\n",
      "\n",
      "Memory usage after optimization: 6.57 MB\n",
      "Memory reduction:--> 84.58%\n"
     ]
    }
   ],
   "source": [
    "# Analyze current data types\n",
    "print(\"=== DATA TYPE OPTIMIZATION ===\")\n",
    "print(\"Current data types:\")\n",
    "print(df_dedupe.dtypes.value_counts())\n",
    "\n",
    "# Check for float columns that could be integers\n",
    "print(\"\\nAnalyzing float64 columns for potential integer conversion:\")\n",
    "float_columns = df_dedupe.select_dtypes(include=[\"float64\"]).columns\n",
    "if float_columns.empty:\n",
    "    print(\"\\n---No float64 columns found that could be converted to integers.\\n\")\n",
    "else:\n",
    "    for col in float_columns:\n",
    "        # Check if all values are whole numbers\n",
    "        if df_dedupe[col].apply(lambda x: x.is_integer()).all():\n",
    "            print(\n",
    "                f\"  {col}: Can be converted to integer since all values are whole numbers\"\n",
    "            )\n",
    "            df_dedupe[col] = df_dedupe[col].astype(\"int32\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"  {col}: Must remain float64 as it contains one or more decimal values\"\n",
    "            )\n",
    "            # Check range to determine if int32 or int64 is appropriate\n",
    "            min_val, max_val = df_dedupe[col].min(), df_dedupe[col].max()\n",
    "            print(f\"   Range: {min_val} to {max_val}\")\n",
    "\n",
    "# Optimize integer columns\n",
    "print(f\"\\nOptimizing integer columns:\")\n",
    "int_columns = df_dedupe.select_dtypes(include=[\"int64\"]).columns\n",
    "for col in int_columns:\n",
    "    min_val, max_val = df_dedupe[col].min(), df_dedupe[col].max()\n",
    "    if min_val >= 0 and max_val <= 255:\n",
    "        df_dedupe[col] = df_dedupe[col].astype(\"uint8\")\n",
    "        print(f\"  {col}: Optimized to uint8 (range: {min_val}-{max_val})\")\n",
    "    elif min_val >= -128 and max_val <= 127:\n",
    "        df_dedupe[col] = df_dedupe[col].astype(\"int8\")\n",
    "        print(f\"  {col}: Optimized to int8 (range: {min_val}-{max_val})\")\n",
    "    elif min_val >= 0 and max_val <= 65535:\n",
    "        df_dedupe[col] = df_dedupe[col].astype(\"uint16\")\n",
    "        print(f\"  {col}: Optimized to uint16 (range: {min_val}-{max_val})\")\n",
    "    else:\n",
    "        df_dedupe[col] = df_dedupe[col].astype(\"int32\")\n",
    "        print(f\"  {col}: Optimized to int32 (range: {min_val}-{max_val})\")\n",
    "\n",
    "print(\n",
    "    f\"\\nMemory usage after optimization: {df_dedupe.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
    ")\n",
    "print(\n",
    "    f\"Memory reduction:--> {((df.memory_usage(deep=True).sum() - df_dedupe.memory_usage(deep=True).sum()) / df.memory_usage(deep=True).sum() * 100):.2f}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06486e1d",
   "metadata": {},
   "source": [
    "üè∑Ô∏è **1. Categorical Feature Encoding**\n",
    "- Q: Which categorical features in the dataset have more than two unique values?\n",
    "- Q: Apply integer-encoding to these high-cardinality features. Why is this strategy suitable for a subsequent neural network with an embedding layer?\n",
    "- Q: Display the first 5 rows of the transformed data to show the new integer labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65365e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical binary features with 2 unique values: ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex', 'Diabetes_binary']\n",
      "Categorical (non-binary) features with more than 2 unique values: ['GenHlth', 'Age', 'Education', 'Income']\n",
      "Numeric/continuous columns: ['BMI', 'MentHlth', 'PhysHlth']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_column_types(df, cardinality_threshold=20):\n",
    "    categorical_binary = []\n",
    "    categorical = []\n",
    "    numeric = []\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        nunique = df[col].nunique()\n",
    "        if dtype == \"object\" or dtype.name == \"category\":\n",
    "            if nunique == 2:\n",
    "                categorical_binary.append(col)\n",
    "            else:\n",
    "                categorical.append(col)\n",
    "        elif pd.api.types.is_integer_dtype(dtype):\n",
    "            if nunique == 2:\n",
    "                categorical_binary.append(col)\n",
    "            elif nunique < cardinality_threshold:\n",
    "                categorical.append(col)\n",
    "            else:\n",
    "                numeric.append(col)\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            numeric.append(col)\n",
    "    return categorical_binary, categorical, numeric\n",
    "\n",
    "\n",
    "cat_bin_cols, cat_cols, num_cols = get_column_types(df_dedupe)\n",
    "print(\"Categorical binary features with 2 unique values:\", cat_bin_cols)\n",
    "print(\"Categorical (non-binary) features with more than 2 unique values:\", cat_cols)\n",
    "print(\"Numeric/continuous columns:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac1b76",
   "metadata": {},
   "source": [
    "üîé Identify high-cardinality categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-cardinality categorical features (more than 2 unique values): ['GenHlth', 'Age', 'Education', 'Income']\n"
     ]
    }
   ],
   "source": [
    "# Identify high cardinality categorical features to encode\n",
    "def identify_high_cardinality_features(df, low_threshold, up_threshold):\n",
    "    \"\"\"\n",
    "    Identify categorical features with more than threshold unique values. High-cardinality categorical variables are good candidates for integer encoding + embeddings in neural networks.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset\n",
    "        threshold (int): Threshold for high cardinality\n",
    "\n",
    "    Returns:\n",
    "        list: High cardinality categorical features\n",
    "    \"\"\"\n",
    "    high_cardinality = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != \"Diabetes_binary\":  # Exclude target\n",
    "            unique_count = df[col].nunique()\n",
    "            # Consider as categorical if it has discrete values and not too many\n",
    "            if low_threshold < unique_count <= up_threshold:\n",
    "                high_cardinality.append(col)\n",
    "    return high_cardinality\n",
    "\n",
    "\n",
    "# Invoke the function with desired thresholds\n",
    "low_threshold = 2\n",
    "up_threshold = 20\n",
    "high_cat_candidates = identify_high_cardinality_features(\n",
    "    df_dedupe, low_threshold, up_threshold\n",
    ")\n",
    "print(\n",
    "    f\"High-cardinality categorical features (more than {low_threshold} unique values):\",\n",
    "    high_cat_candidates,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2fda7",
   "metadata": {},
   "source": [
    "üî§ Integer encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abb7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Integer encoding applied to high-cardinality categorical features.\n",
      "Encoded DataFrame shape: (229474, 22)\n",
      "Sample encoding mappings:\n",
      "  GenHlth: {'1': np.int64(0), '2': np.int64(1), '3': np.int64(2), '4': np.int64(3), '5': np.int64(4)}\n",
      "  Age: {'1': np.int64(0), '10': np.int64(1), '11': np.int64(2), '12': np.int64(3), '13': np.int64(4), '2': np.int64(5), '3': np.int64(6), '4': np.int64(7), '5': np.int64(8), '6': np.int64(9), '7': np.int64(10), '8': np.int64(11), '9': np.int64(12)}\n",
      "  Education: {'1': np.int64(0), '2': np.int64(1), '3': np.int64(2), '4': np.int64(3), '5': np.int64(4), '6': np.int64(5)}\n",
      "  Income: {'1': np.int64(0), '2': np.int64(1), '3': np.int64(2), '4': np.int64(3), '5': np.int64(4), '6': np.int64(5), '7': np.int64(6), '8': np.int64(7)}\n"
     ]
    }
   ],
   "source": [
    "def apply_integer_encoding(df, categorical_features):\n",
    "    \"\"\"\n",
    "    Apply integer encoding to categorical features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset\n",
    "        categorical_features (list): List of categorical features to encode\n",
    "\n",
    "    Returns:\n",
    "        tuple: (encoded_dataframe, encoding_mappings)\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    encoding_mappings = {}\n",
    "\n",
    "    for feature in categorical_features:\n",
    "        if feature in df.columns:\n",
    "            # Create label encoder\n",
    "            le = LabelEncoder()\n",
    "            df_encoded[feature] = le.fit_transform(df[feature].astype(str))\n",
    "\n",
    "            # Store the mapping for reference\n",
    "            encoding_mappings[feature] = {\n",
    "                \"encoder\": le,\n",
    "                \"mapping\": dict(zip(le.classes_, le.transform(le.classes_))),\n",
    "            }\n",
    "\n",
    "    return df_encoded, encoding_mappings\n",
    "\n",
    "\n",
    "# Apply integer encoding\n",
    "df_encoded, enc_maps = apply_integer_encoding(df_dedupe, high_cat_candidates)\n",
    "print(\"‚úÖ Integer encoding applied to high-cardinality categorical features.\")\n",
    "print(\"Encoded DataFrame shape:\", df_encoded.shape)\n",
    "print(\"Sample encoding mappings:\")\n",
    "for feature, mapping in enc_maps.items():\n",
    "    print(f\"  {feature}: {mapping['mapping']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe0b8d",
   "metadata": {},
   "source": [
    "üìè Analyze scaling requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0e73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features identified for scaling: ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
      "\n",
      "Feature: HighBP\n",
      "  mean: 0.45434341145402096\n",
      "  std: 0.4979121973713543\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: HighChol\n",
      "  mean: 0.44164044728378815\n",
      "  std: 0.49658356519075136\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: CholCheck\n",
      "  mean: 0.9594812484203004\n",
      "  std: 0.19717289815963487\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: BMI\n",
      "  mean: 28.687507081412274\n",
      "  std: 6.789204221543287\n",
      "  min: 12\n",
      "  max: 98\n",
      "  range: 86\n",
      "  scale_factor: 8.16666665986111\n",
      "  needs_scaling: False\n",
      "  No scaling needed.\n",
      "\n",
      "Feature: Smoker\n",
      "  mean: 0.4658000470641554\n",
      "  std: 0.4988300788594443\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Stroke\n",
      "  mean: 0.04481553465752111\n",
      "  std: 0.2068992243971703\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: HeartDiseaseorAttack\n",
      "  mean: 0.10333632568395548\n",
      "  std: 0.3043983135036296\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: PhysActivity\n",
      "  mean: 0.7330416517775434\n",
      "  std: 0.442371383934113\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Fruits\n",
      "  mean: 0.6126750743003565\n",
      "  std: 0.4871399816878677\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Veggies\n",
      "  mean: 0.7945867505686919\n",
      "  std: 0.4040041555051357\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: HvyAlcoholConsump\n",
      "  mean: 0.06079120074605402\n",
      "  std: 0.23894744081049157\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: AnyHealthcare\n",
      "  mean: 0.9460113128284686\n",
      "  std: 0.22599586589023207\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: NoDocbcCost\n",
      "  mean: 0.09292120240201504\n",
      "  std: 0.29032261340165244\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: GenHlth\n",
      "  mean: 1.6018198140094302\n",
      "  std: 1.0649620814999694\n",
      "  min: 0\n",
      "  max: 4\n",
      "  range: 4\n",
      "  scale_factor: 400000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: MentHlth\n",
      "  mean: 3.5098660414687504\n",
      "  std: 7.717643069178909\n",
      "  min: 0\n",
      "  max: 30\n",
      "  range: 30\n",
      "  scale_factor: 3000000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: PhysHlth\n",
      "  mean: 4.681218787313595\n",
      "  std: 9.050877330337046\n",
      "  min: 0\n",
      "  max: 30\n",
      "  range: 30\n",
      "  scale_factor: 3000000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: DiffWalk\n",
      "  mean: 0.18575089116849838\n",
      "  std: 0.3889063598176813\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Sex\n",
      "  mean: 0.43908678107323706\n",
      "  std: 0.4962767907563875\n",
      "  min: 0\n",
      "  max: 1\n",
      "  range: 1\n",
      "  scale_factor: 100000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Age\n",
      "  mean: 6.635257153315844\n",
      "  std: 4.0380200932924355\n",
      "  min: 0\n",
      "  max: 12\n",
      "  range: 12\n",
      "  scale_factor: 1200000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Education\n",
      "  mean: 3.9797406242101503\n",
      "  std: 0.9929894498827151\n",
      "  min: 0\n",
      "  max: 5\n",
      "  range: 5\n",
      "  scale_factor: 500000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n",
      "\n",
      "Feature: Income\n",
      "  mean: 4.888614832181424\n",
      "  std: 2.092887904781605\n",
      "  min: 0\n",
      "  max: 7\n",
      "  range: 7\n",
      "  scale_factor: 700000000.0\n",
      "  needs_scaling: True\n",
      "  Scaling needed due to: Values span multiple orders of magnitude\n"
     ]
    }
   ],
   "source": [
    "def analyze_scaling_requirements(df, target_col=\"Diabetes_binary\"):\n",
    "    \"\"\"\n",
    "    ML models (especially gradient-based ones like neural nets, logistic regression, SVMs) perform poorly if features are on very different scales. This step decides which columns need normalization.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset\n",
    "        target_col (str): Name of the target column\n",
    "\n",
    "    Returns:\n",
    "        dict: Scaling analysis results\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if target_col in numerical_cols:\n",
    "        numerical_cols.remove(target_col)\n",
    "\n",
    "    scaling_analysis = {}\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        col_stats = {\n",
    "            \"mean\": df[col].mean(),\n",
    "            \"std\": df[col].std(),\n",
    "            \"min\": df[col].min(),\n",
    "            \"max\": df[col].max(),\n",
    "            \"range\": df[col].max() - df[col].min(),\n",
    "            \"scale_factor\": df[col].max()\n",
    "            / (df[col].min() + 1e-8),  # Avoid division by zero\n",
    "        }\n",
    "\n",
    "        # Determine if scaling is needed\n",
    "        needs_scaling = False\n",
    "        scaling_reason = []\n",
    "\n",
    "        # Check for large range\n",
    "        if col_stats[\"range\"] > 1000:\n",
    "            needs_scaling = True\n",
    "            scaling_reason.append(\"Large range of values\")\n",
    "\n",
    "        # Check for different scales compared to other features\n",
    "        if col_stats[\"scale_factor\"] > 100:\n",
    "            needs_scaling = True\n",
    "            scaling_reason.append(\"Values span multiple orders of magnitude\")\n",
    "\n",
    "        # Check standard deviation\n",
    "        if col_stats[\"std\"] > 100:\n",
    "            needs_scaling = True\n",
    "            scaling_reason.append(\"High standard deviation\")\n",
    "\n",
    "        col_stats[\"needs_scaling\"] = needs_scaling\n",
    "        col_stats[\"scaling_reason\"] = scaling_reason\n",
    "\n",
    "        scaling_analysis[col] = col_stats\n",
    "\n",
    "    return scaling_analysis\n",
    "\n",
    "\n",
    "# 3) Analyze scaling needs\n",
    "scaling_report = analyze_scaling_requirements(df_encoded, target_col=\"Diabetes_binary\")\n",
    "features_to_scale = [k for k, v in scaling_report.items() if v[\"needs_scaling\"]]\n",
    "print(\"Features identified for scaling:\", features_to_scale)\n",
    "for feature, stats in scaling_report.items():\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    for stat, value in stats.items():\n",
    "        if stat != \"scaling_reason\":\n",
    "            print(f\"  {stat}: {value}\")\n",
    "    if stats[\"needs_scaling\"]:\n",
    "        print(f\"  Scaling needed due to: {', '.join(stats['scaling_reason'])}\")\n",
    "    else:\n",
    "        print(\"  No scaling needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785efd0c",
   "metadata": {},
   "source": [
    "üîß Apply feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature scaling applied using StandardScaler.\n",
      "Scaled DataFrame shape: (229474, 22)\n"
     ]
    }
   ],
   "source": [
    "def apply_feature_scaling(df, features_to_scale, scaling_method=\"standard\"):\n",
    "    \"\"\"\n",
    "    Apply scaling to specified features. Scaling prevents features with large magnitudes from dominating the model. Choice depends on algorithm:\n",
    "    StandardScaler ‚Üí good for algorithms assuming Gaussian-like distributions (LogReg, NN).\n",
    "    MinMaxScaler ‚Üí good for bounded features or distance-based algorithms (KNN, Neural Nets with ReLU).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset\n",
    "        features_to_scale (list): Features to scale\n",
    "        scaling_method (str): 'standard' or 'minmax'\n",
    "\n",
    "    Returns:\n",
    "        tuple: (scaled_dataframe, scaler_objects)\n",
    "    \"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    scalers = {}\n",
    "\n",
    "    for feature in features_to_scale:\n",
    "        if feature in df.columns:\n",
    "            if scaling_method == \"standard\":\n",
    "                scaler = StandardScaler()\n",
    "            elif scaling_method == \"minmax\":\n",
    "                scaler = MinMaxScaler()\n",
    "            else:\n",
    "                raise ValueError(\"scaling_method must be 'standard' or 'minmax'\")\n",
    "\n",
    "            # Fit and transform the feature\n",
    "            df_scaled[feature] = scaler.fit_transform(df[[feature]])\n",
    "            scalers[feature] = scaler\n",
    "\n",
    "    return df_scaled, scalers\n",
    "\n",
    "\n",
    "# Apply scaling\n",
    "df_scaled, scalers = apply_feature_scaling(\n",
    "    df_encoded, features_to_scale, scaling_method=\"standard\"\n",
    ")\n",
    "print(\"‚úÖ Feature scaling applied using StandardScaler.\")\n",
    "print(\"Scaled DataFrame shape:\", df_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514755ea",
   "metadata": {},
   "source": [
    "‚úÇÔ∏è Stratified train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c5b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data split into train, validation, and test sets.\n",
      "Train set shape: (160631, 21), Validation set shape: (34421, 21), Test set shape: (34422, 21)\n"
     ]
    }
   ],
   "source": [
    "def perform_stratified_split(\n",
    "    df,\n",
    "    target_col=\"Diabetes_binary\",\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform stratified splitting of the dataset. For imbalanced data (like diabetes prediction where positives < negatives), stratification ensures all splits reflect original class proportions. Otherwise, validation/test may contain very few positive cases.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset\n",
    "        target_col (str): Name of the target column\n",
    "        train_size (float): Proportion for training set\n",
    "        val_size (float): Proportion for validation set\n",
    "        test_size (float): Proportion for test set\n",
    "        random_state (int): Random state for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    \"\"\"\n",
    "    # Validate split sizes\n",
    "    if abs(train_size + val_size + test_size - 1.0) > 1e-6:\n",
    "        raise ValueError(\"Split sizes must sum to 1.0\")\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    # First split: separate test set\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Second split: separate train and validation from remaining data\n",
    "    val_size_adjusted = val_size / (train_size + val_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp,\n",
    "        y_temp,\n",
    "        test_size=val_size_adjusted,\n",
    "        stratify=y_temp,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = perform_stratified_split(\n",
    "    df_scaled,\n",
    "    target_col=\"Diabetes_binary\",\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    ")\n",
    "print(\"‚úÖ Data split into train, validation, and test sets.\")\n",
    "print(\n",
    "    f\"Train set shape: {X_train.shape}, Validation set shape: {X_val.shape}, Test set shape: {X_test.shape}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2645c",
   "metadata": {},
   "source": [
    "‚úÖ Verify stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cdd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stratification verified across splits.\n"
     ]
    }
   ],
   "source": [
    "def verify_stratification(\n",
    "    y_train, y_val, y_test, set_names=[\"Train\", \"Validation\", \"Test\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Verify that stratification was successful by comparing class distributions.\n",
    "\n",
    "    Args:\n",
    "        y_train, y_val, y_test: Target arrays for each set\n",
    "        set_names (list): Names for the sets\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Class distribution comparison\n",
    "    \"\"\"\n",
    "    distributions = []\n",
    "\n",
    "    for y_set, name in zip([y_train, y_val, y_test], set_names):\n",
    "        value_counts = pd.Series(y_set).value_counts().sort_index()\n",
    "        proportions = pd.Series(y_set).value_counts(normalize=True).sort_index()\n",
    "\n",
    "        distributions.append(\n",
    "            {\n",
    "                \"Set\": name,\n",
    "                \"Total_Samples\": len(y_set),\n",
    "                \"Class_0_Count\": value_counts.get(0, 0),\n",
    "                \"Class_1_Count\": value_counts.get(1, 0),\n",
    "                \"Class_0_Proportion\": proportions.get(0, 0),\n",
    "                \"Class_1_Proportion\": proportions.get(1, 0),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(distributions)\n",
    "\n",
    "\n",
    "# Verify stratification\n",
    "verify_stratification(y_train, y_val, y_test)\n",
    "print(\"‚úÖ Stratification verified across splits.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9d22a",
   "metadata": {},
   "source": [
    "üßæ Feature engineering summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Engineering Summary ===\n",
      "data_transformation: {'original_shape': (229474, 22), 'processed_shape': (229474, 22), 'features_encoded': 4, 'features_scaled': 20}\n",
      "encoding_details: {'GenHlth': {'original_unique_values': 5, 'encoding_type': 'Integer Encoding', 'mapping_preview': {'1': np.int64(0), '2': np.int64(1), '3': np.int64(2), '4': np.int64(3), '5': np.int64(4)}}, 'Age': {'original_unique_values': 13, 'encoding_type': 'Integer Encoding', 'mapping_preview': {'1': np.int64(0), '10': np.int64(1), '11': np.int64(2), '12': np.int64(3), '13': np.int64(4)}}, 'Education': {'original_unique_values': 6, 'encoding_type': 'Integer Encoding', 'mapping_preview': {'1': np.int64(0), '2': np.int64(1), '3': np.int64(2), '4': np.int64(3), '5': np.int64(4)}}, 'Income': {'original_unique_values': 8, 'encoding_type': 'Integer Encoding', 'mapping_preview': {'1': np.int64(0), '2': np.int64(1), '3': np.int64(2), '4': np.int64(3), '5': np.int64(4)}}}\n",
      "scaling_details: {'HighBP': {'scaling_type': 'Standard Scaling', 'mean': 0.45434341145402096, 'scale': 0.49791111247123526}, 'HighChol': {'scaling_type': 'Standard Scaling', 'mean': 0.44164044728378815, 'scale': 0.49658248318558695}, 'CholCheck': {'scaling_type': 'Standard Scaling', 'mean': 0.9594812484203004, 'scale': 0.19717246853991113}, 'Smoker': {'scaling_type': 'Standard Scaling', 'mean': 0.4658000470641554, 'scale': 0.4988289919593547}, 'Stroke': {'scaling_type': 'Standard Scaling', 'mean': 0.04481553465752111, 'scale': 0.20689877358476932}, 'HeartDiseaseorAttack': {'scaling_type': 'Standard Scaling', 'mean': 0.10333632568395548, 'scale': 0.3043976502506137}, 'PhysActivity': {'scaling_type': 'Standard Scaling', 'mean': 0.7330416517775434, 'scale': 0.44237042005178673}, 'Fruits': {'scaling_type': 'Standard Scaling', 'mean': 0.6126750743003565, 'scale': 0.4871389202593129}, 'Veggies': {'scaling_type': 'Standard Scaling', 'mean': 0.7945867505686919, 'scale': 0.4040032752211043}, 'HvyAlcoholConsump': {'scaling_type': 'Standard Scaling', 'mean': 0.06079120074605402, 'scale': 0.23894692016828126}, 'AnyHealthcare': {'scaling_type': 'Standard Scaling', 'mean': 0.9460113128284686, 'scale': 0.2259953734681884}, 'NoDocbcCost': {'scaling_type': 'Standard Scaling', 'mean': 0.09292120240201504, 'scale': 0.2903219808181578}, 'GenHlth': {'scaling_type': 'Standard Scaling', 'mean': 1.6018198140094302, 'scale': 1.0649597610557322}, 'MentHlth': {'scaling_type': 'Standard Scaling', 'mean': 3.5098660414687504, 'scale': 7.717626253218326}, 'PhysHlth': {'scaling_type': 'Standard Scaling', 'mean': 4.681218787313595, 'scale': 9.05085760939439}, 'DiffWalk': {'scaling_type': 'Standard Scaling', 'mean': 0.18575089116849838, 'scale': 0.3889055124302136}, 'Sex': {'scaling_type': 'Standard Scaling', 'mean': 0.43908678107323706, 'scale': 0.49627570941965343}, 'Age': {'scaling_type': 'Standard Scaling', 'mean': 6.635257153315844, 'scale': 4.038011294856681}, 'Education': {'scaling_type': 'Standard Scaling', 'mean': 3.9797406242101503, 'scale': 0.9929872862595341}, 'Income': {'scaling_type': 'Standard Scaling', 'mean': 4.888614832181424, 'scale': 2.092883344591377}}\n",
      "data_splits: {'train_size': 160631, 'val_size': 34421, 'test_size': 34422}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_feature_engineering_summary(\n",
    "    original_df,\n",
    "    processed_df,\n",
    "    encoding_mappings,\n",
    "    scalers,\n",
    "    split_info,\n",
    "    *,\n",
    "    as_dfs=False,\n",
    "    verbose=False,\n",
    "    mapping_preview_n=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary of feature engineering steps.\n",
    "\n",
    "    Args:\n",
    "        original_df (pd.DataFrame): Original dataset\n",
    "        processed_df (pd.DataFrame): Processed dataset\n",
    "        encoding_mappings (dict): {feature: {'encoder': LabelEncoder, 'mapping': {orig:str->int}}}\n",
    "        scalers (dict): {feature: fitted scaler}\n",
    "        split_info (dict): Any metadata about splits (sizes, ratios, etc.)\n",
    "        as_dfs (bool): If True, also return tidy DataFrames for display\n",
    "        verbose (bool): If True, pretty-print a human-readable summary\n",
    "        mapping_preview_n (int): How many mapping items to preview per encoded feature\n",
    "\n",
    "    Returns:\n",
    "        dict (always): 'summary' dict with details\n",
    "        dict of DataFrames (optional, when as_dfs=True):\n",
    "            {'overview': df, 'encoding': df, 'scaling': df, 'splits': df}\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        \"data_transformation\": {\n",
    "            \"original_shape\": original_df.shape,\n",
    "            \"processed_shape\": processed_df.shape,\n",
    "            \"features_encoded\": len(encoding_mappings),\n",
    "            \"features_scaled\": len(scalers),\n",
    "        },\n",
    "        \"encoding_details\": {},\n",
    "        \"scaling_details\": {},\n",
    "        \"data_splits\": split_info if isinstance(split_info, dict) else {},\n",
    "    }\n",
    "\n",
    "    # Encoding details\n",
    "    for feature, mapping in encoding_mappings.items():\n",
    "        mp = mapping.get(\"mapping\", {})\n",
    "        preview_items = list(mp.items())[:mapping_preview_n]\n",
    "        summary[\"encoding_details\"][feature] = {\n",
    "            \"original_unique_values\": len(mp),\n",
    "            \"encoding_type\": \"Integer Encoding\",\n",
    "            \"mapping_preview\": dict(preview_items),\n",
    "        }\n",
    "\n",
    "    # Scaling details\n",
    "    for feature, scaler in scalers.items():\n",
    "        if hasattr(scaler, \"mean_\"):  # StandardScaler\n",
    "            summary[\"scaling_details\"][feature] = {\n",
    "                \"scaling_type\": \"Standard Scaling\",\n",
    "                \"mean\": float(scaler.mean_[0]),\n",
    "                \"scale\": float(scaler.scale_[0]),\n",
    "            }\n",
    "        elif hasattr(scaler, \"min_\"):  # MinMaxScaler\n",
    "            summary[\"scaling_details\"][feature] = {\n",
    "                \"scaling_type\": \"MinMax Scaling\",\n",
    "                \"min\": float(scaler.min_[0]),\n",
    "                \"scale\": float(scaler.scale_[0]),\n",
    "            }\n",
    "        else:\n",
    "            summary[\"scaling_details\"][feature] = {\n",
    "                \"scaling_type\": type(scaler).__name__,\n",
    "                \"details\": \"Scaler does not expose mean_/min_ attributes\",\n",
    "            }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=== Data Transformation ===\")\n",
    "        print(f\"Original shape:  {summary['data_transformation']['original_shape']}\")\n",
    "        print(f\"Processed shape: {summary['data_transformation']['processed_shape']}\")\n",
    "        print(f\"Features encoded: {summary['data_transformation']['features_encoded']}\")\n",
    "        print(\n",
    "            f\"Features scaled:  {summary['data_transformation']['features_scaled']}\\n\"\n",
    "        )\n",
    "\n",
    "        print(\"=== Encoding Details ===\")\n",
    "        if summary[\"encoding_details\"]:\n",
    "            for feat, det in summary[\"encoding_details\"].items():\n",
    "                print(\n",
    "                    f\"- {feat}: {det['encoding_type']} (unique={det['original_unique_values']})\"\n",
    "                )\n",
    "                print(f\"  preview: {det['mapping_preview']}\")\n",
    "        else:\n",
    "            print(\"  (none)\")\n",
    "        print()\n",
    "\n",
    "        print(\"=== Scaling Details ===\")\n",
    "        if summary[\"scaling_details\"]:\n",
    "            for feat, det in summary[\"scaling_details\"].items():\n",
    "                print(\n",
    "                    f\"- {feat}: {det['scaling_type']} | { {k:v for k,v in det.items() if k!='scaling_type'} }\"\n",
    "                )\n",
    "        else:\n",
    "            print(\"  (none)\")\n",
    "        print()\n",
    "\n",
    "        if summary[\"data_splits\"]:\n",
    "            print(\"=== Data Splits ===\")\n",
    "            pprint(summary[\"data_splits\"])\n",
    "            print()\n",
    "\n",
    "    if not as_dfs:\n",
    "        return summary\n",
    "\n",
    "    # Build nice DataFrames for display\n",
    "    overview_df = pd.DataFrame([summary[\"data_transformation\"]])\n",
    "\n",
    "    if summary[\"encoding_details\"]:\n",
    "        enc_rows = []\n",
    "        for feat, det in summary[\"encoding_details\"].items():\n",
    "            enc_rows.append(\n",
    "                {\n",
    "                    \"feature\": feat,\n",
    "                    \"encoding_type\": det[\"encoding_type\"],\n",
    "                    \"original_unique_values\": det[\"original_unique_values\"],\n",
    "                    \"mapping_preview\": json.dumps(det[\"mapping_preview\"]),\n",
    "                }\n",
    "            )\n",
    "        encoding_df = pd.DataFrame(enc_rows).sort_values(\"feature\")\n",
    "    else:\n",
    "        encoding_df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"feature\",\n",
    "                \"encoding_type\",\n",
    "                \"original_unique_values\",\n",
    "                \"mapping_preview\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if summary[\"scaling_details\"]:\n",
    "        sc_rows = []\n",
    "        for feat, det in summary[\"scaling_details\"].items():\n",
    "            row = {\"feature\": feat, \"scaling_type\": det.get(\"scaling_type\", \"\")}\n",
    "            for k, v in det.items():\n",
    "                if k != \"scaling_type\":\n",
    "                    row[k] = v\n",
    "            sc_rows.append(row)\n",
    "        scaling_df = pd.DataFrame(sc_rows).sort_values(\"feature\")\n",
    "    else:\n",
    "        scaling_df = pd.DataFrame(\n",
    "            columns=[\"feature\", \"scaling_type\", \"mean\", \"scale\", \"min\"]\n",
    "        )\n",
    "\n",
    "    if summary[\"data_splits\"]:\n",
    "        splits_df = pd.DataFrame([summary[\"data_splits\"]])\n",
    "    else:\n",
    "        splits_df = pd.DataFrame()\n",
    "\n",
    "    return summary, {\n",
    "        \"overview\": overview_df,\n",
    "        \"encoding\": encoding_df,\n",
    "        \"scaling\": scaling_df,\n",
    "        \"splits\": splits_df,\n",
    "    }\n",
    "\n",
    "\n",
    "# Summarize feature engineering\n",
    "split_info = {\n",
    "    \"train_size\": len(y_train),\n",
    "    \"val_size\": len(y_val),\n",
    "    \"test_size\": len(y_test),\n",
    "}\n",
    "summary = generate_feature_engineering_summary(\n",
    "    df_dedupe, df_scaled, enc_maps, scalers, split_info\n",
    ")\n",
    "print(\"=== Feature Engineering Summary ===\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd361c1f",
   "metadata": {},
   "source": [
    "üîÅ Before/after comparison (stats only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d21aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison stats for selected features:\n",
      "- HighBP:\n",
      "  Original: {'mean': np.float64(0.4290011037527594), 'std': np.float64(0.4949344626899013), 'min': np.int64(0), 'max': np.int64(1)}\n",
      "  Processed: {'mean': np.float64(-1.367369166492327e-16), 'std': np.float64(1.0000021789032056), 'min': np.float64(-0.9124990386316569), 'max': np.float64(1.0958915655402288)}\n",
      "- HighChol:\n",
      "  Original: {'mean': np.float64(0.4241209397666351), 'std': np.float64(0.49420980465688485), 'min': np.int64(0), 'max': np.int64(1)}\n",
      "  Processed: {'mean': np.float64(-5.152405554898623e-17), 'std': np.float64(1.0000021789032054), 'min': np.float64(-0.8893596980116083), 'max': np.float64(1.1244044476444752)}\n",
      "- CholCheck:\n",
      "  Original: {'mean': np.float64(0.9626695048880479), 'std': np.float64(0.1895707543627255), 'min': np.int64(0), 'max': np.int64(1)}\n",
      "  Processed: {'mean': np.float64(-7.134099999090401e-17), 'std': np.float64(1.0000021789032056), 'min': np.float64(-4.866202951788296), 'max': np.float64(0.20549903279979448)}\n",
      "- Smoker:\n",
      "  Original: {'mean': np.float64(0.44316855881425415), 'std': np.float64(0.49676066677856323), 'min': np.int64(0), 'max': np.int64(1)}\n",
      "  Processed: {'mean': np.float64(2.080779166401367e-17), 'std': np.float64(1.0000021789032056), 'min': np.float64(-0.9337870383887179), 'max': np.float64(1.0709079896049265)}\n",
      "- Stroke:\n",
      "  Original: {'mean': np.float64(0.04057079785556607), 'std': np.float64(0.19729409940016232), 'min': np.int64(0), 'max': np.int64(1)}\n",
      "  Processed: {'mean': np.float64(-4.8551513882698564e-17), 'std': np.float64(1.0000021789032054), 'min': np.float64(-0.21660609138004175), 'max': np.float64(4.616675337377611)}\n"
     ]
    }
   ],
   "source": [
    "def create_before_after_comparison(original_df, processed_df, features_to_compare):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing features before and after processing.\n",
    "\n",
    "    (Note: This function returns stats; you can add your own visualizations in separate cells.)\n",
    "\n",
    "    Args:\n",
    "        original_df (pd.DataFrame): Original dataset\n",
    "        processed_df (pd.DataFrame): Processed dataset\n",
    "        features_to_compare (list): Features to compare\n",
    "\n",
    "    Returns:\n",
    "        dict: Comparison statistics and visualizations\n",
    "    \"\"\"\n",
    "    comparisons = {}\n",
    "\n",
    "    for feature in features_to_compare:\n",
    "        if feature in original_df.columns and feature in processed_df.columns:\n",
    "            comparison = {\n",
    "                \"original_stats\": {\n",
    "                    \"mean\": original_df[feature].mean(),\n",
    "                    \"std\": original_df[feature].std(),\n",
    "                    \"min\": original_df[feature].min(),\n",
    "                    \"max\": original_df[feature].max(),\n",
    "                },\n",
    "                \"processed_stats\": {\n",
    "                    \"mean\": processed_df[feature].mean(),\n",
    "                    \"std\": processed_df[feature].std(),\n",
    "                    \"min\": processed_df[feature].min(),\n",
    "                    \"max\": processed_df[feature].max(),\n",
    "                },\n",
    "            }\n",
    "            comparisons[feature] = comparison\n",
    "\n",
    "    return comparisons\n",
    "\n",
    "\n",
    "# Compare before/after for selected features\n",
    "Compare_stats = create_before_after_comparison(df, df_scaled, features_to_scale[:5])\n",
    "print(\"Comparison stats for selected features:\")\n",
    "for feature, stats in Compare_stats.items():\n",
    "    print(f\"- {feature}:\")\n",
    "    print(f\"  Original: {stats['original_stats']}\")\n",
    "    print(f\"  Processed: {stats['processed_stats']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
